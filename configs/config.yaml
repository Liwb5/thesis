# multi processing with calculating rewards
# multiply reward with 1000 to make the loss more sensitive
# using rouge_f to calculate reward
# using tanh and explorate_rate==5 to contrain the result of attention alpha, so that sample can explorate
# loss function can avoid nan value 
# using multi sample instead of exponential moving avg reward
# learning rate 0.00005
task_name: train.rl_advantage_R_1000Rewards_explorate_rate5.v2_0.big.0121  # this is the name of the task
device: 0    # if you do not want to use GPU, set null
log_level: info 
use_summaryWriter: True
seed: 1667
loss: nll_loss
metrics: rouge_metric

optimizer: 
    type: Adam
    args:
        lr: 0.00005
    
trainer:
    type: Trainer
    args:
        epochs: 30
        save_period: 1
        print_loss_every: 20                   # print train loss every [num] batches, related to the batch size
        print_token_every: 1000000000             # print training tokens to see the result. print every [num] batches 
        print_val_token_every: 500000000         # print val tokens to see the result. print every [num] batches 
        do_validation: True 
        max_norm: 1.0
        epsilon: 0.9    # the initial probability of exploration
        save_dir: checkpoints/
        log_dir: logs/
        teacher_forcing_ratio: 0.9
        output_dir: outputs/

data_loader:
    train_data: ./data/dm_data_from_summaRuNNer/origin_data/train.json
    val_data: ./data/dm_data_from_summaRuNNer/origin_data/val.json
    test_data: ./data/dm_data_from_summaRuNNer/origin_data/test.json
    batch_size: 20
    shuffle: True
    val_data_quota: 10000
    data_quota: -1


vocabulary: 
    vocab_file: ./data/dm_data_from_summaRuNNer/origin_data/w2i.json
    embed_file: ./data/dm_data_from_summaRuNNer/origin_data/embedding.npz
    sent_trunc: 120
    doc_trunc: 50


lr_scheduler: 
    type: StepLR
    args: 
        step_size: 50
        gamma: 0.1
    
model: 
    type: RL_AE
    args: 
        embed_dim: 100
        vocab_size: 153826
        hidden_size: 128
        max_len: 120
        sos_id: 2
        eos_id: 3
        max_selected: 4
        rnn_cell: gru
        input_dropout_p: 0.0 
        dropout_p: 0.0 
        bidirectional: True
        use_attention: False
        select_mode: distribute 
        explorate_rate: 5
        sample_num: 5
